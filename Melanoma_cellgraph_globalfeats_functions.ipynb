{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d61a94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from numpy.linalg import lstsq\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn import utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from patchify import patchify, unpatchify\n",
    "from keras import utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from patchify import patchify, unpatchify\n",
    "from keras import utils\n",
    "import skimage\n",
    "\n",
    "from skimage import measure, io, img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb, rgb2gray\n",
    "import numpy as np\n",
    "import gc\n",
    "from skimage import measure, color, io\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "\n",
    "from skimage import measure, io, img_as_ubyte\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb, rgb2gray\n",
    "import numpy as np\n",
    "import gc\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import measure, color, io\n",
    "from keras.models import Model\n",
    "from itertools import repeat\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa426dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_list(points, distance):\n",
    "    edge_list_1st_row = []\n",
    "    edge_list_2nd_row = []\n",
    "    dist_list = []\n",
    "    for i in range(len(points)):\n",
    "        dist = np.sqrt((points[i,0] - points[:,0])**2 + (points[i,1] - points[:,1])**2)\n",
    "        dist = dist.reshape(-1,1)\n",
    "        #print(dist)\n",
    "        x = np.where(dist<=distance)\n",
    "        node_index = list(x[0])\n",
    "        dist_list.append(np.average(dist[node_index]))\n",
    "        edge_list_2nd_row.append(node_index)\n",
    "        edge_list_1st_row.extend(repeat(i,len(node_index)))\n",
    "    edge_list_2nd_row = [item for sublist in edge_list_2nd_row for item in sublist]\n",
    "    edge_list = [edge_list_1st_row, edge_list_2nd_row]\n",
    "    edge_list = np.array(edge_list)\n",
    "    dist_list = np.array(dist_list)\n",
    "    dist_list = dist_list.reshape(-1,1)\n",
    "    return edge_list, dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(edge_list):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list.T)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afae5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d610d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eccent(G, bool_get_90=True, verbose = True):\n",
    "    temp_gen = nx.shortest_path_length( G)\n",
    "    short_path_len = [list(temp[1].values()) for temp in temp_gen]\n",
    "    try:\n",
    "        avg_short_path = nx.average_shortest_path_length(G)\n",
    "    except:\n",
    "        avg_short_path = np.inf\n",
    "        \n",
    "    eccent_L = []\n",
    "        \n",
    "    if bool_get_90:\n",
    "        eccent_90_L = []\n",
    "        \n",
    "    for sub_len_list in short_path_len:\n",
    "        eccent_L.append(np.max(sub_len_list))\n",
    "            \n",
    "        if bool_get_90:\n",
    "            eccent_90_L.append(np.percentile(sub_len_list, 90, overwrite_input = True))\n",
    "    \n",
    "    eccent = np.array( eccent_L)\n",
    "    if bool_get_90:\n",
    "        eccent_90 = np.array( eccent_90_L) \n",
    "        \n",
    "    return eccent, eccent_90, avg_short_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1eabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_slope( eig, low, high):\n",
    "    \n",
    "    eig_abs = np.sort(eig)\n",
    "    idx = np.where( (eig_abs>=low) & (eig_abs<high))[0]\n",
    "    x = np.arange( idx.shape[0])\n",
    "    y = eig_abs[idx]\n",
    "    \n",
    "    m,c = fit_line_mul( x, y)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566edefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats_spect( G, eps = 1e-10, \n",
    "                    library = 0, \n",
    "                    bool_eig_symm = True):\n",
    "    \n",
    "    #\"Global Graph Features for Spectral Measures:\"\n",
    "    #available:  [20, 21, 23, 25, 26, 27, 28, 29, 30]\n",
    "    #omitted:    [22, 24]\n",
    "    \n",
    "    \n",
    "    #Metrics related to adjacency matrix\n",
    "    \n",
    "    if library == 1:\n",
    "        A = np.array(G.get_adjacency().data)\n",
    "    else:\n",
    "        A = nx.adj_matrix(G).toarray()\n",
    "        \n",
    "    if not bool_eig_symm:\n",
    "        eig = scipy.linalg.eig( A, right = False).astype(float)        \n",
    "    else:        \n",
    "        eig = scipy.linalg.eigh( A, eigvals_only = True)\n",
    "    \n",
    "    idx = np.flip( np.argsort(np.abs(eig)))\n",
    "    eig = eig[idx]\n",
    "    \n",
    "    eig_1 = eig[0]\n",
    "    eig_2 = eig[1]    \n",
    "    \n",
    "    energy = np.sum(eig**2)\n",
    "    \n",
    "    #Metrics related to normalized Laplacian    \n",
    "\n",
    "    if library == 1:\n",
    "        L_n = np.array( G.laplacian(normalized = True))\n",
    "    else:\n",
    "        L_n = nx.linalg.normalized_laplacian_matrix(G).toarray()        \n",
    "    \n",
    "    if not bool_eig_symm:\n",
    "        eig_L_n = scipy.linalg.eig( L_n, right = False).astype(float)\n",
    "    else:\n",
    "        eig_L_n = scipy.linalg.eigh( L_n, eigvals_only = True)\n",
    "    \n",
    "#    num_zeros = np.sum( np.abs(eig_L_n)< eps)\n",
    "    \n",
    "    lower_slope = _get_slope( eig_L_n, low = 0, high = 1)\n",
    "    num_ones = np.sum( np.abs(eig_L_n - 1)< eps)\n",
    "    \n",
    "    upper_slope = _get_slope( eig_L_n, low = 1, high = 2)\n",
    "    \n",
    "    num_twos = np.sum( np.abs(eig_L_n - 2)< eps) #L_n\n",
    "    trace_L_n = np.trace(L_n)\n",
    "    energy_L_n = np.sum(eig_L_n**2)\n",
    "    \n",
    "    return  [eig_1, eig_2,\n",
    "            energy, lower_slope,\n",
    "            num_ones, upper_slope,\n",
    "            num_twos, trace_L_n, energy_L_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line( p1, p2):\n",
    "    \n",
    "    '''\n",
    "    In:\n",
    "        p1:     2,\n",
    "        p2:     2,\n",
    "    Test:\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot( [p1[0],p2[0]],[p1[1],p2[1]],'*')\n",
    "    \n",
    "    x = np.arange(np.min( [p1[0],p2[0]]),\n",
    "                  np.max( [p1[0],p2[0]]),100)\n",
    "    \n",
    "    y_est = x*m+c\n",
    "    \n",
    "    ax.plot( x, y_est, '.')\n",
    "    '''\n",
    "    \n",
    "    X = np.vstack( [np.ones([2]),[p1[0],p2[0]]]).T\n",
    "    y = np.hstack( [p1[1],p2[1]])\n",
    "    \n",
    "    c, m = lstsq( X, y, rcond = None)[0]\n",
    "    \n",
    "    return m, c\n",
    "\n",
    "def fit_line_mul( X_in, y):\n",
    "    \n",
    "    '''\n",
    "    In:\n",
    "        X:  N,\n",
    "        y:  N,\n",
    "    '''\n",
    "    \n",
    "    X = np.vstack( [np.ones_like(X_in),X_in]).T\n",
    "    \n",
    "    c, m = lstsq( X, y, rcond = None)[0]\n",
    "    \n",
    "    return m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8813de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphFeats( G, library = 0, bool_spect = True):\n",
    "    \n",
    "    '''\n",
    "    Extract the graph features.\n",
    "    \n",
    "    lcc stands for largest connected component\n",
    "    \n",
    "    In:\n",
    "        G:              #Graph object should be consistent with library\n",
    "        library:        #0: Uses networkx, 1: Uses igraph\n",
    "        bool_spect:     #Turn on or off calculating spectral features\n",
    "    \n",
    "    TODO\n",
    "        -Possible mismatch between libs in sparsely connected graphs.\n",
    "        -Edge weights euclidean distance.\n",
    "    '''        \n",
    "        \n",
    "    if library == 0:\n",
    "        \n",
    "        v_count = G.number_of_nodes()\n",
    "        e_count = G.number_of_edges()\n",
    "        \n",
    "        #\n",
    "        avg_clus = nx.average_clustering(G)                \n",
    "            \n",
    "        degree = np.array( G.degree(np.arange(v_count)))[:,1]\n",
    "#        closeness = np.array( list(nx.closeness_centrality(G).items()))[:,1]\n",
    "        \n",
    "        #\n",
    "        Gcc = sorted( nx.connected_components(G), key=len, reverse=True)\n",
    "        G0 = G.subgraph(Gcc[0])     #Largest Connected Component\n",
    "        \n",
    "        e_count_G0 = G0.size()\n",
    "        CC_count = len(Gcc)        \n",
    "    \n",
    "#        eccent_lcc = np.array( list(nx.eccentricity( G0).items()))[:,1]\n",
    "\n",
    "#        try:\n",
    "#            avg_short_path = nx.average_shortest_path_length(G)\n",
    "#        except:\n",
    "#            avg_short_path = np.nan\n",
    "        \n",
    "    elif library == 1:\n",
    "        \n",
    "        v_count = G.vcount()\n",
    "        e_count = G.ecount()\n",
    "        \n",
    "        clus = np.array(G.transitivity_local_undirected())\n",
    "        #If number of neighbors is zero or one, than clus=0\n",
    "        clus[np.isnan(clus)] = 0\n",
    "        avg_clus = np.average( clus)\n",
    "        \n",
    "        #\n",
    "#        eccent = np.array( G.eccentricity())\n",
    "        degree = np.array( G.degree())\n",
    "#        closeness = np.array( G.closeness())\n",
    "    \n",
    "        # https://lists.nongnu.org/archive/html/igraph-help/2016-01/msg00015.html\n",
    "        cl = G.clusters()\n",
    "        G0 = cl.giant()\n",
    "        \n",
    "        e_count_G0 = G0.ecount()\n",
    "        CC_count = len(cl.sizes())\n",
    "        \n",
    "#        eccent_lcc = np.array( G0.eccentricity())\n",
    "        \n",
    "        short_path_len = G.shortest_paths_dijkstra()\n",
    "        avg_short_path = np.sum(short_path_len)/(v_count*(v_count-1))\n",
    "        \n",
    "        if np.isinf( avg_short_path):\n",
    "            avg_short_path = np.nan\n",
    "        \n",
    "    eccent, eccent_90, avg_short_path = get_eccent(G, bool_get_90=True, verbose = True)\n",
    "    \n",
    "    avg_deg = np.average( degree)\n",
    "    avg_eccent = np.average( eccent)\n",
    "    diameter = np.max( eccent)\n",
    "    radius = np.min( eccent)\n",
    "\n",
    "    cent_p_count = np.where( eccent == radius)[0].shape[0]\n",
    "    \n",
    "    avg_eccent_90 = np.average( eccent_90)\n",
    "    diameter_90 = np.max( eccent_90)\n",
    "    radius_90 = np.min( eccent_90)\n",
    "    \n",
    "#    avg_closs = np.average( closeness)\n",
    "    \n",
    "    if v_count != 0 and e_count != 0:\n",
    "        \n",
    "        per_cent_points = cent_p_count/v_count*100\n",
    "        \n",
    "        ratio_size_LCC = e_count_G0/e_count    \n",
    "        \n",
    "        iso_v_count = np.where( degree == 0)[0].shape[0]\n",
    "        perct_isolated = iso_v_count/v_count*100\n",
    "        \n",
    "        end_v_count = np.where( degree == 1)[0].shape[0]\n",
    "        perct_end = end_v_count/v_count*100\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        per_cent_points = np.nan\n",
    "        ratio_size_LCC = np.nan\n",
    "        \n",
    "        perct_isolated = np.nan\n",
    "        perct_end = np.nan\n",
    "    \n",
    "    \n",
    "    #\"Global Graph Features for Connectedness and Cliquishness Measures\"    \n",
    "    #available:  [1,2,12,13,14,15]\n",
    "    #omitted:    [3,4]\n",
    "    \n",
    "    feat_set_1 = [avg_deg,          avg_clus,\n",
    "                 ratio_size_LCC,    CC_count, \n",
    "                 perct_isolated,    perct_end]\n",
    "    \n",
    "    #\"Global Graph Features for Distance Based (Shortest-path related) Measures:\"\n",
    "    #available:  [5,6,7,8,9,10,11,16,17,18,19]\n",
    "    #omitted:    []\n",
    "    \n",
    "    feat_set_2 = [avg_eccent,   diameter,\n",
    "                  radius,       avg_eccent_90,\n",
    "                  diameter_90,  radius_90,\n",
    "                  avg_short_path,\n",
    "                  cent_p_count,\n",
    "                  per_cent_points,\n",
    "                  v_count,      e_count]\n",
    "    \n",
    "    if bool_spect: \n",
    "        feat_set_3 = get_feats_spect( G, library = library)\n",
    "        \n",
    "        return np.array(feat_set_1 + feat_set_2 +\\\n",
    "                        feat_set_3)\n",
    "    else:\n",
    "        return np.array(feat_set_1 + feat_set_2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat = scipy.io.loadmat('Humayun/seeds_img1.mat')\n",
    "\n",
    "# Extract the list from the mat dictionary\n",
    "seeds_img1 = mat['seeds_img1'][0]  # The [0] is because the loaded data might be in 2D array format\n",
    "\n",
    "print(seeds_img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d55de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc23062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d91d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b9975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c5879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
